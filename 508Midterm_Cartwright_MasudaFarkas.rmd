---
title: "Hedonic Home Price Prediction in Boulder County"
subtitle: "Team: Simon & Garfunkel Tribute Band"
author: "Alex Cartwright & Max Masuda-Farkas"
date: "22 October 2021"
output:
  html_document:
    toc: true
    toc_float: TRUE
    number_sections: true
    code_folding: hide
---

# Introduction

Determining the value of a home is becoming increasingly mechanized. With the  maturation of statistical modeling techniques and machine learning, a process that was once driven largely by negotiations between individual actors—and the hard-to-measure factor of human taste—can now be abstracted by computers. The purpose of this project is to do just that: to devise a machine learning model that can accurately predict the sale price of a home based on both intrinsic and environmental factors.

Before any discussion of the techniques used to design this model, it is important to emphasize what, and whom, such a thing benefits. We do not believe that machines should learn merely for learning’s sake. A model that can predict home prices, however, stands to benefit many interests. The most obvious, of course, is home buyers and sellers who can refer to the model as a benchmark, obviating much of the needless back-and-forth that characterizes real estate negotiations.

But there are others who would be better off, too. Neighbors ought to have a sense of their local real estate market given that the value of one home tends to influence that of the next. Local governments, agencies, and other public service providers would also be beneficiaries since they need an accurate measure of the local economy to craft good policy. Finally, foreign investors and businesses that funnel private capital and create jobs in cities are not usually equipped with the local intelligence necessary to make investment decisions, relying inefficiently on the word of locals. An automated valuation model can help to give them that information easily.

The model used in this project is what is known as a hedonic model. Not to be confused with the ancient Greek school of philosophy, hedonic models refer to predictive models that synthesize a variety of discrete factors to derive a final prediction. Here, our hedonic model for home price predictions takes input factors from three primary categories: (1) the physical attributes of each property, (2) nearby public amenities or disamenities, and (3) the clustering of home prices in physical space (also known in the real estate industry as “comparables” or “comps”). A detailed list of the specific factors used in our model follows in the Data section below.

The accuracy of our results can be assessed using a host of different metrics, but the most salient is the adjusted R^2 value, measuring how much variation in price is explained by the model. The predictive model here returned an adjusted R^2 value of approximately 0.516, indicating that just over 50% of the variation was explained by the model. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(tidycensus)
library(sf)
library(viridis)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot)
library(kableExtra)
library(stargazer)

root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")

options(scipen = 999)
```

```{r, out.width = "400px", echo = FALSE}
knitr::include_graphics("Simon_and_Garfunkel_1968_poster.png")
```

# Data

Every piece of data that was fed into the model falls under one of the three categories stated above (see Introduction). Although the bulk of the data on each home’s internal attributes was already given (e.g. square footage, number of rooms, etc.), data from the second and third categories—that is, nearby amenities or disamenities and spatial patterns—needed to be sourced externally. 

Public data sources that were used to do so include the U.S. Census Bureau for demographic information, the State of Colorado’s open data portal for the locations of schools, and Boulder County’s open data portal for local ZIP codes and points of interest for recreation such as trailheads.

```{r data wrangling, include = FALSE, message = FALSE, warning = FALSE}
# ----- create boulder_homes geojson dataset, convert to sf, condition data -----
boulder_homes <- 
  st_read("studentData.geojson", crs = 'ESRI:102254') %>%
  mutate(price_per_sf = price / TotalFinishedSF) %>%
  mutate(Age = 2021 - builtYear)

boulder_homes$AcDscr = ifelse(is.na(boulder_homes$Ac) | 
                              boulder_homes$Ac == 200,
                              "No AC", boulder_homes$AcDscr)

# There are a dozen or so home records with 1 or 0 sq.ft. of finished area.
# These records are removed because they are not representative of the full data.
boulder_homes <- boulder_homes %>%
  dplyr::filter(TotalFinishedSF > 1)

boulder_boundary <-
  st_read("County_Boundary.geojson") %>%
  st_transform('ESRI:102254')

# ----- Census Data Wrangling -----
var19 <- load_variables(2019, "acs5", cache = TRUE)

acs_vars <- c(
  "B19013_001E", # Med HH Income
  "B06010_001E", # total earners
  "B06010_011E", # number of earners making over $75K
  "C24070_001E", # Labor force
  "C24070_002E", # Agriculture, forestry, fishing and hunting, and mining
  "C24070_003E", # Construction
  "C24070_004E", # Manufacturing
  "C24070_005E", # Wholesale trade
  "C24070_006E", # Retail trade
  "C24070_007E", # Transportation and warehousing, and utilities
  "C24070_008E", # Information
  "C24070_009E", # Finance and insurance, and real estate, and rental and leasing
  "C24070_010E", # Professional, scientific, and management, and administrative, and waste management services
  "C24070_011E", # Educational services, and  health care and social assistance
  "C24070_012E") # Arts, entertainment, and recreation, and accommodation and food services

acsTractsBoulder.2019.sf <- get_acs(geography = "tract",
                                   year = 2019, 
                                   variables = acs_vars, 
                                   geometry = TRUE, 
                                   state = "CO", 
                                   county = "Boulder", 
                                   output = "wide") %>%
  st_transform('ESRI:102254')

acsTractsBoulder.2019.sf <- acsTractsBoulder.2019.sf %>%
  dplyr::select(GEOID, NAME, all_of(acs_vars)) %>%
  rename(med_HH_Income = B19013_001E,
         tot_earners = B06010_001E,
         over75K = B06010_011E,
         employed = C24070_001E,
         Ag_Mining = C24070_002E,
         Construction = C24070_003E,
         Manufacturing = C24070_004E,
         Wholesale = C24070_005E,
         Retail = C24070_006E,
         Transportation = C24070_007E,
         Information = C24070_008E,
         Finance = C24070_009E,
         Professional = C24070_010E,
         Ed_Health = C24070_011E,
         ArtsRecEnt = C24070_012E) %>%
  mutate(
         pct.over75K = over75K/tot_earners,
         pct.Ag_Mining = Ag_Mining/employed,
         pct.Construction = Construction/employed,
         pct.Manufacturing = Manufacturing/employed,
         pct.Wholesale = Wholesale/employed,
         pct.Retail = Retail/employed,
         pct.Transportation = Transportation/employed,
         pct.Information = Information/employed,
         pct.Finance = Finance/employed,
         pct.Professional = Professional/employed,
         pct.Ed_Health = Ed_Health/employed,
         pct.ArtsRecEnt = ArtsRecEnt/employed)

censusFactors <- acsTractsBoulder.2019.sf %>%
  select(med_HH_Income, pct.over75K, pct.Information, pct.Finance, pct.Professional,
         pct.Ed_Health)

boulder_homes <-
  st_join(boulder_homes, censusFactors)

# ----- Front Range polyline factor -----

FrontRange = st_read("FrontRange.shp") %>%
  st_transform('ESRI:102254')

boulder_homes <- boulder_homes %>%
  mutate(dist_FR = as.numeric(st_distance(., FrontRange)))

# ----- Municipal Boundaries of Boulder County -----
munis <- st_read("https://opendata.arcgis.com/datasets/9597d3916aba47e887ca563d5ac15938_0.geojson") %>%
  st_transform('ESRI:102254') %>%
  dplyr::select(ZONEDESC, geometry) %>%
  rename(Municipality = ZONEDESC)

boulder_homes <-
  st_join(boulder_homes, munis)

boulder_homes$Municipality = ifelse(is.na(boulder_homes$Municipality),
                              "Not Incorporated", boulder_homes$Municipality)

# ----- Zip Codes of Boulder County -----
boulder_zips <-
  st_read("https://opendata.arcgis.com/datasets/6b6091f299204e4c9c406a624baf43e6_10.geojson") %>%
  st_transform('ESRI:102254') %>%
  st_intersection(boulder_boundary, boulder_zips) %>%
  # filter only zip codes and geometry
  dplyr::select(GEOID10, geometry) %>%
  rename(ZipCode = GEOID10)

boulder_homes <-
  st_join(boulder_homes, boulder_zips)

# ----- School Data Wrangling -----
boulder_schools <-
  st_read("./colorado_schools.geojson") %>%
  st_transform('ESRI:102254') %>%
  st_intersection(boulder_boundary, boulder_schools) %>%
  filter(Type_ %in% c("Non-Public School Mailing Address",
         "Public School Physical Address"))

group_by(boulder_schools, Type_) %>%
  summarize(count = n())

st_c <- st_coordinates

boulder_homes <-
  boulder_homes %>% 
    mutate(
      schools_nn3 = nn_function(st_c(boulder_homes), st_c(boulder_schools), 3))

# ----- Trailheads Data Wrangling -----
trailheads <-
  st_read("https://opendata.arcgis.com/datasets/3a950053bbef46c6a3c2abe3aceee3de_0.geojson") %>%
  st_transform('ESRI:102254') %>%
  st_intersection(boulder_boundary, trailheads)

boulder_homes <- boulder_homes %>% 
    mutate(
      trailheads_nn5 = nn_function(st_c(boulder_homes), st_c(trailheads), 5))
```

```{r split dataset into observed and predict, include = FALSE}
boulder_homes_observed <- boulder_homes %>%
  dplyr::filter(toPredict == 0)

boulder_homes_predict <- boulder_homes %>%
  dplyr::filter(toPredict == 1)
```

```{r build the model dataset, include=FALSE}
# Select variables from boulder_homes_observed 
feature_list <-
  c("price", "med_HH_Income", "pct.over75K", "pct.Information", "pct.Finance",
    "pct.Professional","pct.Ed_Health", "nbrBedRoom", "nbrFullBaths",
    "TotalFinishedSF", "AcDscr", "Age", "schools_nn3", "trailheads_nn5", "dist_FR",
    "qualityCodeDscr", "designCodeDscr", "ZipCode", "Municipality")

boulder.sf <- boulder_homes_observed %>% 
  select(feature_list)
```

## Regression Summary Statistics

```{r regression 1, include=FALSE, message=FALSE, warning=FALSE, echo=TRUE}
reg1 <- lm(price ~ ., data = st_drop_geometry(boulder.sf) %>%
             dplyr::select("price", "med_HH_Income", "pct.over75K", "pct.Information",
                           "pct.Finance", "pct.Professional","pct.Ed_Health",
                           "nbrBedRoom", "nbrFullBaths","TotalFinishedSF", "AcDscr",
                           "Age", "schools_nn3", "trailheads_nn5", "dist_FR", 
                           "qualityCodeDscr", "designCodeDscr", "ZipCode"))
```

A summary of regression statistics for the variables used in the predictive model is presented below.

```{r summary of reg1, results="asis", message=FALSE, echo=FALSE}
# summarytable1 <- data.frame(stargazer(reg1, type = "text"))

stargazer(reg1, type = "html")
```

## Correlation Matrix

The correlation matrix below depicts how related or unrelated each feature is to the others. For instance, how far a home is from the Front Range appears to be negatively correlated to price, i.e. closeness to the Front Range corresponds to higher price. (Importantly, note that correlation is distinct from causation and that the matrix only serves as a helpful guide for determining relevant factors for the model.)

``` {r correlation matrix, include=TRUE, warning=FALSE, message=FALSE}
numericVars <- 
  select_if(st_drop_geometry(boulder.sf), is.numeric) %>% na.omit()

ggcorrplot(
  round(cor(numericVars), 1), 
  p.mat = cor_pmat(numericVars),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +   
    labs(title = "Correlation across numeric variables",
         caption = "Figure 1.1")
```

## Variable Correlation Scatterplots

Scatterplots are another means of showing correlation. The four features shown here are (moving clockwise beginning from the top left): (1) percentage of the population with income greater than $75,000 per year, (2) percentage of the population associated with professional or management services, (3) the average of the distances to the nearest five trailheads, and (4) the average of the distances to the nearest three schools.

The first two demographic features are positively correlated with price, meaning that a greater share of the population with higher income and in professional services corresponds to higher price. Contrariwise, homes that are further away from trailheads and schools correspond to lower prices. 

```{r numerical variable scatterplots, include=TRUE, warning=FALSE, message=FALSE}
st_drop_geometry(boulder.sf) %>%
  dplyr::select(price, pct.over75K, pct.Professional, schools_nn3, trailheads_nn5) %>%
  filter(price <= 4000000) %>%
  gather(Variable, Value, -price) %>% 
   ggplot(aes(Value, price)) +
     geom_point(size = .5) + geom_smooth(method = "lm", se=F, colour = "#FA7800") +
     facet_wrap(~Variable, ncol = 2, scales = "free") +
     labs(title = "Price as a function of continuous variables",
          caption = "Figure 1.2") +
     plotTheme()
```

## Spatial Distribution of Home Sale Prices in Boulder County

Although homes are sold for a wide range of prices across Boulder County, the prices that these homes have fetched tends to cluster in space. The following map demonstrates this phenomenon.

```{r sale price map}
# Price per square foot
ggplot() +
  geom_sf(data = boulder_boundary, fill = NA, colour = "black") +
  geom_sf(data = boulder.sf, aes(colour = q5(price)), 
          show.legend = "point", size = .75) +
  scale_colour_manual(values = palette5,
                   labels=qBr(boulder.sf,"price"),
                   name="Quintile\nBreaks") +
  labs(title="Home Sale Prices, Boulder County",
       caption = "Figure 1.3") +
  mapTheme()
```

## Mapping Independent Variables

Just as the model’s outcome variable, home sale price, can be depicted on the map, so too can the features that the model will use to predict that outcome. Three of these features are mapped here.

First, the distance between each home and the Front Range is color-coded accordingly below, with the Front Range itself included for reference.

```{r map of distance from front range}
# Distance from the Front Range
ggplot() +
  geom_sf(data = boulder_boundary, fill = NA, colour = "black") +
  geom_sf(data = FrontRange, colour = "#2d6a4f", size = 2) +
  geom_sf(data = boulder_homes_observed, aes(colour = q5(dist_FR)), 
          show.legend = "point", size = .75) +
  scale_colour_manual(values = palette5,
                   labels=qBr(boulder_homes,"dist_FR"),
                   name="Quintile\nBreaks") +
  labs(title="Home distance from Front Range",
       caption = "Figure 1.4") +
  mapTheme()
```

One of the U.S. Census variables, median household income, is mapped by Census tract.

```{r map of medHHincome}
# Median Household Income in Boulder County
ggplot() + 
  geom_sf(data = boulder_boundary, fill = NA, colour = "black") +
  geom_sf(data = acsTractsBoulder.2019.sf, aes(fill = med_HH_Income)) +
  scale_fill_viridis_b() +
  labs(title = "Median Household Income in Boulder County",
       subtitle = "by Census Tract",
       caption = "Figure 1.5") +
  mapTheme()
```

Another amenity/public service factor used in the model is the proximity of a home to schools. Figure 1.6 presents the distribution of schools, both public and private, in Boulder County. 

```{r map of schools in Boulder County}
# Distance from the Front Range
ggplot() +
  geom_sf(data = boulder_boundary, fill = NA, colour = "black") +
  geom_sf(data = boulder_schools, colour = "#2d6a4f", show.legend = "point") +
  labs(title = "Schools in Boulder County",
       caption = "Figure 1.6") +
  mapTheme()
```

Finally, Zip Code areas for the county are used to examine the spatial structure of home price in figure 1.7. It is apparent that some zip codes host a higher percentage of high value homes compared to others.

```{r sale price and zip codes}
# Sale Price + zipcodes
ggplot() +
  geom_sf(data = boulder_boundary, fill = NA, colour = "black") +
  geom_sf(data = acsTractsBoulder.2019.sf, fill = NA, colour = "#55286F") +
  geom_sf(data = boulder_homes_observed, aes(colour = q5(price)), 
          show.legend = "point", size = .75) +
  scale_colour_manual(values = palette5,
                   labels=qBr(boulder_homes,"price"),
                   name="Quintile\nBreaks") +
  labs(title="Home Sale Prices + Zip Code Areas",
       caption = "Figure 1.7") +
  mapTheme()
```

# Methods

The type of statistical model used here is called a Linear Regression, or an Ordinary Least Squares regression. This type of model synthesizes a list of relevant components to produce a function representing the distribution of individual observations. In this case, the model was derived from the various data features described above, factoring in each home’s internal and environmental characteristics to predict price.

The strength of a prediction model can be distilled down to two interrelated qualities: accuracy and generalizability.

Accuracy refers to the ability of a model to produce predicted values that are as close as possible to the actual observed values. To test the accuracy of the model here, the original data was divided into two groups. One group, the training set, represented 75% of the original data and was used to create, or “train,” the regression model. The second group, the test set, represented the remaining 25% of the data and was used to measure how close, or not, the predictions came to the corresponding observed values. Accuracy can be measured by the metrics of “mean absolute error” (MAE) and “mean absolute percent error” (MAPE).

Generalizability refers to the ability of a model to make predictions based on new, unseen data. The generalizability of the model here was tested using a method known as k-fold cross-validation, using 100 folds. The full dataset was divided into 100 subsets, and 100 regressions are performed, each round leaving one subset out of the data to be used as the test set for that round. Price prediction errors across all 100 subsets were averaged to capture how well the model performs on data that it has yet to encounter.

# Results

```{r PartionData, include=FALSE, warning=FALSE, message=FALSE}
inTrain <- createDataPartition(y = paste(boulder.sf$qualityCodeDscr, boulder.sf$designCodeDscr, boulder.sf$ZipCode, boulder.sf$AcDscr),
                               p = 0.75, list = FALSE)

boulder.training <- boulder.sf[inTrain,]
boulder.test <- boulder.sf[-inTrain,]

reg.training <- lm(price ~ ., data = as.data.frame(boulder.training) %>%
                  dplyr::select("price", "med_HH_Income", "pct.over75K", "pct.Information","pct.Finance", "pct.Professional","pct.Ed_Health",
                           "nbrBedRoom", "nbrFullBaths","TotalFinishedSF", "AcDscr",
                           "Age", "schools_nn3", "trailheads_nn5", "dist_FR", 
                           "qualityCodeDscr", "designCodeDscr", "ZipCode"))
```

As discussed, the dataset was split into a training set and a test set. The following summary table presents the results of the linear regression on the training data set.

```{r summary of training regression, results="asis", message=FALSE, echo=FALSE}
stargazer(reg.training, type = "html")
```

## Initial Test Set Results

```{r predict on test set, include=FALSE, warning=FALSE, message=FALSE}
boulder.test <-
  boulder.test %>%
  mutate(Regression = "Baseline Regression",
         price.predict = predict(reg.training, boulder.test),
         price.error = price.predict - price,
         price.abserror = abs(price.predict - price),
         price.ape = (abs(price.predict - price)) / price.predict)%>%
  filter(price < 5000000)
```

A summary of the mean absolute error and mean average percent error (MAPE) for the price prediction on the test data set is shown below.

``` {r summary statistics for test set, include = TRUE, warning=FALSE, message=FALSE}
mean(boulder.sf$price, na.rm = T)
test.MAE <- c(mean(boulder.test$price.abserror, na.rm = T))
test.MAPE <- c(mean(boulder.test$price.ape, na.rm = T))
test.SumStats <- data.frame(test.MAE, test.MAPE)

test.SumStats %>%
  kable(col.names = c("MAE", "MAPE"), caption = "Test Set Error Metrics")
```

Graphic representations of the results of the test set prediction are shown below. The histogram shows that the absolute price errors are generally concentrated around the mean, but there are some very large errors.

```{r ACCURACY//visualize, include=TRUE, warning=FALSE, message=FALSE}
# histogram of absolute errors
ggplot(boulder.test, aes(x = price.abserror)) +
  geom_histogram(binwidth=10000, fill = "green", colour = "white") +
  scale_x_continuous(limits = c(0, 1000000)) +
  labs(title = "Distribution of prediction errors for single test",
       x = "Sale Price Absolute Error", y = "Count",
       caption = "Figure 4.1") +
  plotTheme()
```

## Cross Validation Results

```{r cross validation, include=TRUE, warning=FALSE, message=FALSE}
fitControl <- trainControl(method = "cv", number = 100)
set.seed(825)

reg.cv <- 
  train(price ~ ., data = st_drop_geometry(boulder.sf), 
     method = "lm", trControl = fitControl, na.action = na.pass)
```

K-fold cross validation with 100 folds is used to explore the generalizability of this model. A histogram of the mean average error across the 100 folds is shown below. These results indicate that the model is somewhat generalizable, but there are situations where the predictions are highly inaccurate, as seen in the high mean absolute error outlier.

```{r exploring cross validation results, include=TRUE, warning=FALSE, message=FALSE}
# histogram of cross validation MAE
mae <- data.frame(reg.cv$resample[,3]) %>%
  rename(mae = reg.cv.resample...3.)

ggplot(mae, aes(x = mae)) +
  geom_histogram(binwidth=10000, fill = "orange", colour = "white") +
  scale_x_continuous(labels = c(0, 100000, 200000, 300000, 400000, 500000), 
                     limits = c(0, 500000)) +
  labs(title = "Distribution of MAE",
       subtitle = "k-fold cross validation; k = 100",
       x = "Mean Absolute Error", y = "Count",
       caption = "Figure 4.2") +
  plotTheme()
```

### Exploring Test Set Prediction Error

The prices predicted for the test set are plotted against the actual sale prices for the test set in the figure below. As observed sale price increases, this predictive model tends to under-predict the value of a home, demonstrated by the widening gap between the green line (actual prediction trend) and the orange line (perfect prediction) in the plot below.

```{r predicted vs observed, include=TRUE, message=FALSE}
ggplot(boulder.test) +
  geom_point(aes(price, price.predict)) +
  geom_smooth(aes(price, price), colour = "orange") +
  geom_smooth(method = "lm", aes(price, price.predict), se = FALSE, colour = "green") +
  labs(title = "Predicted sale price as a function of observed price",
       subtitle = "Orange line represents a perfect prediction; Green line represents prediction",
       x = "Observed Sale Price", y = "Predicted Sale Price",
       caption = "Figure 4.3") +
  plotTheme()
```

Residual absolute errors for the test set are mapped onto Boulder County below.

```{r test set residual errors, include = TRUE}
ggplot() +
  geom_sf(data = boulder_boundary, fill = "grey") +
  geom_sf(data = boulder.test, aes(colour = q5(price.abserror)), 
          show.legend = "point", size = .75) +
  scale_colour_manual(values = palette5,
                   labels=qBr(boulder.test,"price.abserror"),
                   name="Quintile\nBreaks") +
  labs(title="Test set absolute price errors",
       caption = "Figure 4.4") +
  mapTheme()
```

Because of the geographically clustered nature of real estate, errors in price predictions tend also to cluster in space. This phenomenon is known as the “spatial lag.” The following plot depicts the spatial lag of errors in the model. 

``` {r spatial error lag, include=TRUE, warning=FALSE, message=FALSE}
coords.test <- st_coordinates(boulder.test) 

neighborList.test <- knn2nb(knearneigh(coords.test, 5))

spatialWeights.test <- nb2listw(neighborList.test, style="W")

boulder.test %>%
  mutate(lagPriceError = lag.listw(spatialWeights.test, price.error)) %>%
  ggplot(aes(lagPriceError, price.error)) +
     geom_point(size = .5) + geom_smooth(method = "lm", se=F, colour = "#FA7800") +
     labs(title = "Error as a function of the spatial lag of price errors",
          x = "Lag of Price Errors", y = "Price Error",
          caption = "Figure 4.5") +
     plotTheme()
```

The clustering effect of home prices—the technical term is “spatial autocorrelation”—can also be demonstrated by the statistic known as Moran’s I. A Moran’s I that nears positive 1 is an indication of clustering, whereas a 0 value indicates a random distribution. In the figure below, the observed Moran’s I, depicted in orange, is contrasted with 999 randomly distributed values, showing that home prices in Boulder do indeed cluster in space.

``` {r morans i, include=TRUE, warning=FALSE, message=FALSE}
moranTest <- moran.mc(boulder.test$price.error,
                      spatialWeights.test, nsim = 999)

ggplot(as.data.frame(moranTest$res[c(1:999)]), aes(moranTest$res[c(1:999)])) +
  geom_histogram(binwidth = 0.01) +
  geom_vline(aes(xintercept = moranTest$statistic), colour = "#FA7800",size=1) +
  scale_x_continuous(limits = c(-1, 1)) +
  labs(title="Observed and permuted Moran's I",
       subtitle= "Observed Moran's I in orange",
       x="Moran's I",
       y="Count",
       caption = "Figure 4.6") +
  plotTheme()
```

### Predictions for full dataset



```{r all predicted values, include=TRUE}
allPredictions <- boulder_homes %>%
  mutate(predictions = predict(reg1, boulder_homes)) %>%
  dplyr::select(predictions)

ggplot() +
  geom_sf(data = boulder_boundary, fill = "grey") +
  geom_sf(data = allPredictions, aes(colour = q5(predictions)), 
          show.legend = "point", size = .75) +
  scale_colour_manual(values = palette5,
                   labels=qBr(allPredictions,"predictions"),
                   name="Quintile\nBreaks") +
  labs(title="Predictions for all homes in the dataset, Boulder County",
       caption = "Figure 4.7") +
  mapTheme()
```


## Generalizability

### Exploring Spatial Structure

Zip Codes were used as a categorical feature in the predictive model to examine the importance of spatial structure in home price. Mapping the prediction errors by Zip Code indicates where the model is lacking clarity on the underlying drivers of home price. Figure 4.8 shows that the home prices in zip codes in the north and west of the county are not well understood by the model.

```{r map of MAPE by Zip Code, include = TRUE, message = FALSE, warning = FALSE}
st_drop_geometry(boulder.test) %>%
  group_by(ZipCode) %>%
  summarize(mean.MAPE = mean(price.ape, na.rm = T)) %>%
  ungroup() %>% 
  left_join(boulder_zips) %>%
    st_sf() %>%
    ggplot() + 
      geom_sf(aes(fill = mean.MAPE)) +
      geom_sf(data = boulder.test, colour = "black", size = .5) +
      scale_fill_gradient(low = palette5[1], high = palette5[5],
                          name = "MAPE") +
      labs(title = "Mean test set MAPE by Zip Code",
           caption = "Figure 4.8") +
      mapTheme()
```

The table below and the scatterplot in Figure 4.9 also indicate that the model is decent at predicting in different spatial regimes within the county, but performs poorly in a few cases. Further investigation is required to understand the underlying causes of poor predictions in certain regions.

```{r MAPE by zip vs mean price by zip, include = TRUE, message = FALSE, warning = FALSE}
testError_by_zips <-
left_join(
  st_drop_geometry(boulder.test) %>%
    group_by(ZipCode) %>%
    summarize(meanPrice = mean(price, na.rm = T)),
  st_drop_geometry(boulder.test) %>%
    group_by(ZipCode) %>%
    summarize(MAPE = mean(price.ape)))

testError_by_zips %>%
  kable() %>% kable_styling()
```

```{r map of test errors by zip, warning=FALSE, message=FALSE}
ggplot(testError_by_zips) +
  geom_point(aes(meanPrice, MAPE)) +
  geom_smooth(method = "lm", aes(meanPrice, MAPE), se = FALSE, colour = "green") +
  labs(title = "MAPE by Zip Code as a function of mean price by Zip Code",
       x = "Mean Home Price", y = "MAPE",
       caption = "Figure 4.9") +
  plotTheme()
```

### Generalizing Across Demographic Groups

The model's generalizability can be evaluated in relation to demographic categories. Below, two Census factors are depicted in Boulder County: race as a function of white vs. non-white and income level.

That Boulder County has a relatively racially homogeneous makeup would seem to indicate that the model is fairly generalizable on that score. Variations in income might present an obstacle to generalizability, in contrast.

(The greatest challenge to the model's generalizability comes in the urban-rural distinction, however, as discussed later in this project.)

```{r generalizability, include=TRUE, warning=FALSE, message=FALSE}
boulder_tracts19 <- 
  get_acs(geography = "tract", year = 2019, 
          variables = c("B01001_001E","B01001A_001E","B06011_001"), 
          geometry = TRUE, state = "CO", county = "Boulder", output = "wide") %>%
  st_transform('ESRI:102254')  %>%
  rename(TotalPop = B01001_001E,
         NumberWhites = B01001A_001E,
         Median_Income = B06011_001E) %>%
  mutate(percentWhite = NumberWhites / TotalPop,
         raceContext = ifelse(percentWhite > .5, "Majority White", "Majority Non-White"),
         incomeContext = ifelse(Median_Income > 32322, "High Income", "Low Income"))

grid.arrange(ncol = 2,
  ggplot() + geom_sf(data = na.omit(boulder_tracts19), 
  aes(fill = raceContext)) +
    scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Race Context") +
    labs(title = "Race Context") +
    mapTheme() + theme(legend.position="bottom"), 
  ggplot() + geom_sf(data = na.omit(boulder_tracts19), 
  aes(fill = incomeContext)) +
    scale_fill_manual(values = c("#25CB10", "#FA7800"), 
    name="Income Context") +
    labs(title = "Income Context") +
    mapTheme() + 
    theme(legend.position="bottom"))
```

# Discussion

The above results suggest that the model was effective in some respects and defective in others. In sum, the model was able to predict just under 50% of the variation in prices. The accuracy of the model varied widely according to the feature. The two that clearly outperformed the rest were distance to schools and the Front Range. Both were highly statistically significant and contributed substantially to the model, particularly when considered in the aggregate.

Conversely, the ZIP codes of each home were, surprisingly, not especially significant on their own. Despite one's common sense intuition about the importance of a house’s ZIP code, the results suggest that on an individual basis, ZIP codes were not strongly determinative of price. That said, it is notable that when in the process of modeling ZIP codes were removed from the model, the overall accuracy declined markedly. That would indicate that ZIP codes, while relatively insignificant on a per-property basis, are integral to the model as a whole.

Both the strength and weakness of the model can be attributed to the geography of Boulder County. The model excelled in urban areas, clustered around Boulder and other large municipalities contained within the greater county. The reason for this is likely that environmental features such as nearness to schools and recreational amenities are of greater importance for homes in the denser parts of the county, whose residents actively consider such elements when purchasing a home.

On the other hand, the model saw a sizable drop in accuracy in the rural parts of the county. Certain properties located further in the mountains were clearly sui generis, with prices that diverged significantly from the rest. The model struggled to account for these properties, likely because many of the features important in urban areas are simply inapposite in the rural context. Homebuyers who are seeking a mountain getaway house, for example, are less interested in their house’s proximity to schools.


# Conclusion
<style>
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px;}
</style>
<div class = "blue">

Although it represents a fine starting point, the model in its present form would likely not be ready for deployment by Zillow. Beyond even the need to improve base metrics such as average error, the more fundamental problems identified in the Discussion section would need to be remedied before Zillow’s vast user base could rely on the model.

Thankfully, several areas for improvement can already be identified. To start, more features should be added. Data which were not included in the model but which would doubtless prove useful include crime data, school districts ranked by desirability, and other features that better account for the clustering effects of home prices, such as neighborhoods. Although these data may not be available in pre-packaged form from the open data sources used here, these obstacles are likely overcome by clever engineering.

To the urban–rural issue articulated in the previous section, one possible solution is to revise the model to predict initially for price per square foot rather than total price. Price per square foot better measures the effect of location on property value, as it is more comparable across properties irrespective of the physical buildings. When coupled with more variables that account for the spatial clustering of price, a price-per-square-foot metric would likely distinguish between urban and rural properties better than the current model.

</div>